{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom functions\n",
    "def daterange(x,y):\n",
    "    dates = pd.date_range(x,y,freq = 'd')\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\n",
      "C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Shraddha.Mishra\\\\OneDrive - Shell\\\\Career_development\\\\Projects\\\\Ultimate Potential South Africa\\\\OneDrive_1_7-25-2024\\\\Sales Data'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.getcwd()\n",
    "print(directory)\n",
    "\n",
    "folder = r\"C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\"\n",
    "print(folder)\n",
    "\n",
    "path = os.path.join(directory,folder)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\\Year_2019.csv\n",
      "C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\\Year_2020.csv\n",
      "C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\\Year_2021.csv\n",
      "C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\\Year_2022.csv\n",
      "C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\\Year_2023.csv\n",
      "C:\\Users\\Shraddha.Mishra\\OneDrive - Shell\\Career_development\\Projects\\Ultimate Potential South Africa\\OneDrive_1_7-25-2024\\Sales Data\\Year_2024.csv\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.DataFrame()\n",
    "for root,dirs,files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            print(os.path.join(root,file))\n",
    "            df = pd.read_csv(os.path.join(root,file))\n",
    "            full_data = pd.concat([df,full_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2781090, 13)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Code             object\n",
       "Distribution Channel     object\n",
       "BL Date                   int64\n",
       "Sales Order Number        int64\n",
       "Material Number           int64\n",
       "Material Text            object\n",
       "Movement Type             int64\n",
       "Receiving Plant Code     object\n",
       "Receiving Plant Name     object\n",
       "Billing Document        float64\n",
       "Ship To                   int64\n",
       "Ship To Name             object\n",
       "Sales Volumes in L15    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Code</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>BL Date</th>\n",
       "      <th>Sales Order Number</th>\n",
       "      <th>Material Number</th>\n",
       "      <th>Material Text</th>\n",
       "      <th>Movement Type</th>\n",
       "      <th>Receiving Plant Code</th>\n",
       "      <th>Receiving Plant Name</th>\n",
       "      <th>Billing Document</th>\n",
       "      <th>Ship To</th>\n",
       "      <th>Ship To Name</th>\n",
       "      <th>Sales Volumes in L15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZA03</td>\n",
       "      <td>Global Retail</td>\n",
       "      <td>20240101</td>\n",
       "      <td>290269393</td>\n",
       "      <td>400003139</td>\n",
       "      <td>SH ULG 95 E0 Dye Umk Coastal V-Power ZA</td>\n",
       "      <td>601</td>\n",
       "      <td>Z166</td>\n",
       "      <td>ZA5500 ZA03 Retail S Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10042741</td>\n",
       "      <td>HERMANUS AUTO STOP</td>\n",
       "      <td>7324.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZA03</td>\n",
       "      <td>Global Retail</td>\n",
       "      <td>20240101</td>\n",
       "      <td>290269393</td>\n",
       "      <td>400003151</td>\n",
       "      <td>SH AGO B0 Udy Umk V-Power Diesel ZA</td>\n",
       "      <td>601</td>\n",
       "      <td>Z166</td>\n",
       "      <td>ZA5500 ZA03 Retail S Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10042741</td>\n",
       "      <td>HERMANUS AUTO STOP</td>\n",
       "      <td>3563.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZA03</td>\n",
       "      <td>Global Retail</td>\n",
       "      <td>20240101</td>\n",
       "      <td>290269393</td>\n",
       "      <td>400006090</td>\n",
       "      <td>SH AGO 50ppmS B0 FSD Mobility Udy Umk ZA</td>\n",
       "      <td>601</td>\n",
       "      <td>Z166</td>\n",
       "      <td>ZA5500 ZA03 Retail S Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10042741</td>\n",
       "      <td>HERMANUS AUTO STOP</td>\n",
       "      <td>1086.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZA03</td>\n",
       "      <td>Global Retail</td>\n",
       "      <td>20240102</td>\n",
       "      <td>290309265</td>\n",
       "      <td>400003139</td>\n",
       "      <td>SH ULG 95 E0 Dye Umk Coastal V-Power ZA</td>\n",
       "      <td>601</td>\n",
       "      <td>Z166</td>\n",
       "      <td>ZA5500 ZA03 Retail S Africa</td>\n",
       "      <td>1.440131e+09</td>\n",
       "      <td>10042741</td>\n",
       "      <td>HERMANUS AUTO STOP</td>\n",
       "      <td>8881.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZA03</td>\n",
       "      <td>Global Retail</td>\n",
       "      <td>20240102</td>\n",
       "      <td>290309265</td>\n",
       "      <td>400003151</td>\n",
       "      <td>SH AGO B0 Udy Umk V-Power Diesel ZA</td>\n",
       "      <td>601</td>\n",
       "      <td>Z166</td>\n",
       "      <td>ZA5500 ZA03 Retail S Africa</td>\n",
       "      <td>1.440131e+09</td>\n",
       "      <td>10042741</td>\n",
       "      <td>HERMANUS AUTO STOP</td>\n",
       "      <td>4798.337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Code Distribution Channel   BL Date  Sales Order Number  \\\n",
       "0         ZA03        Global Retail  20240101           290269393   \n",
       "1         ZA03        Global Retail  20240101           290269393   \n",
       "2         ZA03        Global Retail  20240101           290269393   \n",
       "3         ZA03        Global Retail  20240102           290309265   \n",
       "4         ZA03        Global Retail  20240102           290309265   \n",
       "\n",
       "   Material Number                             Material Text  Movement Type  \\\n",
       "0        400003139   SH ULG 95 E0 Dye Umk Coastal V-Power ZA            601   \n",
       "1        400003151       SH AGO B0 Udy Umk V-Power Diesel ZA            601   \n",
       "2        400006090  SH AGO 50ppmS B0 FSD Mobility Udy Umk ZA            601   \n",
       "3        400003139   SH ULG 95 E0 Dye Umk Coastal V-Power ZA            601   \n",
       "4        400003151       SH AGO B0 Udy Umk V-Power Diesel ZA            601   \n",
       "\n",
       "  Receiving Plant Code         Receiving Plant Name  Billing Document  \\\n",
       "0                 Z166  ZA5500 ZA03 Retail S Africa               NaN   \n",
       "1                 Z166  ZA5500 ZA03 Retail S Africa               NaN   \n",
       "2                 Z166  ZA5500 ZA03 Retail S Africa               NaN   \n",
       "3                 Z166  ZA5500 ZA03 Retail S Africa      1.440131e+09   \n",
       "4                 Z166  ZA5500 ZA03 Retail S Africa      1.440131e+09   \n",
       "\n",
       "    Ship To        Ship To Name  Sales Volumes in L15  \n",
       "0  10042741  HERMANUS AUTO STOP              7324.491  \n",
       "1  10042741  HERMANUS AUTO STOP              3563.254  \n",
       "2  10042741  HERMANUS AUTO STOP              1086.050  \n",
       "3  10042741  HERMANUS AUTO STOP              8881.990  \n",
       "4  10042741  HERMANUS AUTO STOP              4798.337  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['date'] = pd.to_datetime(full_data['BL Date'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding External Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_list = [400003103,400003118,400003139,400003151,400003154,400003159,400006090]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2781090, 14)\n"
     ]
    }
   ],
   "source": [
    "print(full_data.shape)\n",
    "full_data = full_data[full_data['Material Number'].isin(material_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624953, 14)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code is adding holiday information to a sales data set, processing it to ensure that the holidays are correctly integrated, and handling any missing data. Here's a breakdown of what each part of the code does:\n",
    "\n",
    "### 1. **Loading the Holidays Data**\n",
    "```python\n",
    "folder = 'External Variables'\n",
    "file = 'SA Holiday Calendar.xlsx'\n",
    "holidays = pd.read_excel(os.path.join(directory, folder, file))\n",
    "```\n",
    "- **folder** and **file**: These variables define the location and name of the holiday data file.\n",
    "- **holidays**: This reads the holiday calendar from an Excel file (`SA Holiday Calendar.xlsx`) and loads it into a pandas DataFrame named `holidays`.\n",
    "\n",
    "### 2. **Saving the Holidays Data to CSV**\n",
    "```python\n",
    "subfolder = 'EDA'\n",
    "subfolder_1 = 'External Vars Processed'\n",
    "filename = 'holidays.csv'\n",
    "\n",
    "write_path = os.path.join(directory, subfolder, subfolder_1, filename)\n",
    "holidays.to_csv(write_path)\n",
    "```\n",
    "- **subfolder** and **subfolder_1**: These define the directory structure where the holidays data will be saved as a CSV file.\n",
    "- **write_path**: The full path where the CSV file will be saved.\n",
    "- **holidays.to_csv(write_path)**: This saves the `holidays` DataFrame to a CSV file at the specified path.\n",
    "\n",
    "### 3. **Merging Holidays with Sales Data**\n",
    "```python\n",
    "full_data_timeseries = pd.merge(full_data, holidays, left_on = 'date', right_on = 'Holiday', how = 'left')\n",
    "```\n",
    "- **pd.merge**: Merges the sales data (`full_data`) with the holidays data (`holidays`).\n",
    "- **left_on = 'date'**: The key in `full_data` for merging is the 'date' column.\n",
    "- **right_on = 'Holiday'**: The key in the `holidays` DataFrame for merging is the 'Holiday' column.\n",
    "- **how = 'left'**: A left join is performed, meaning all records from `full_data` will be retained, and matching records from `holidays` will be added.\n",
    "\n",
    "### 4. **Handling Missing Data**\n",
    "```python\n",
    "full_data_timeseries = full_data_timeseries.drop('Holiday', axis = 1)\n",
    "full_data_timeseries['Holiday Desc'] = full_data_timeseries['Holiday Desc'].fillna('NA')\n",
    "full_data_timeseries['Holiday_Grouping'] = full_data_timeseries['Holiday_Grouping'].fillna('NA')\n",
    "full_data_timeseries['Holiday Flag'] = full_data_timeseries['Holiday Flag'].fillna(0)\n",
    "```\n",
    "- **drop('Holiday', axis = 1)**: The 'Holiday' column is dropped from the `full_data_timeseries` DataFrame since it's no longer needed after the merge.\n",
    "- **fillna('NA')**: Missing values (`NaN`) in the 'Holiday Desc' and 'Holiday_Grouping' columns are filled with 'NA'. This indicates that no holiday was present on those dates.\n",
    "- **fillna(0)**: Missing values in the 'Holiday Flag' column are filled with `0`, indicating no holiday on those dates.\n",
    "\n",
    "### Summary\n",
    "This code is processing sales data by integrating holiday information. After merging the sales data with the holidays, it cleans up the result by removing unnecessary columns and filling in missing values to ensure the data is complete and consistent. This would be useful for understanding the impact of holidays on sales performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624953, 17)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding Holidays\n",
    "folder = \"External Variables\"\n",
    "file = 'SA Holiday Calendar.xlsx'\n",
    "holidays = pd.read_excel(os.path.join(directory,folder,file))\n",
    "\n",
    "#Writing Holidays file\n",
    "subfolder = 'EDA'\n",
    "subfolder_1 = 'External Vars Processed'\n",
    "filename = 'holidays.csv'\n",
    "\n",
    "write_path = os.path.join(directory, subfolder,subfolder_1,filename)\n",
    "\n",
    "holidays.to_csv(write_path)\n",
    "\n",
    "#full_data means sales data of the year\n",
    "full_data_timeseries = pd.merge(full_data,holidays,left_on = 'date',right_on = 'Holiday', how = 'left')\n",
    "\n",
    "full_data_timeseries = full_data_timeseries.drop('Holiday',axis=1)\n",
    "full_data_timeseries[['Holiday Desc','Holiday_Grouping']] = full_data_timeseries[['Holiday Desc','Holiday_Grouping']].fillna('NA')\n",
    "# full_data_timeseries['Holiday_Grouping'] = full_data_timeseries[\n",
    "full_data_timeseries['Holiday Flag'] = full_data_timeseries['Holiday Flag'].fillna(0)\n",
    "\n",
    "full_data_timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624953, 19)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Lockdowns\n",
    "folder = 'External Variables'\n",
    "file = 'SA Lockdown.xlsx'\n",
    "lockdowns = pd.read_excel(os.path.join(directory,folder,file))\n",
    "\n",
    "# The DataFrame is filtered to include only those rows where 'End Date' is not missing.\n",
    "# The result is reassigned to the lockdowns DataFrame.\n",
    "lockdowns = lockdowns[~lockdowns['End Date'].isna()]\n",
    "\n",
    "lockdowns['Date_Range'] = lockdowns.apply(lambda x: daterange(x['Start Date'] , x['End Date']), axis =1)\n",
    "\n",
    "# Expand Lists into Rows: The explode() function is used to transform each element of a list-like column into its own row,\n",
    "# duplicating the values of other columns accordingly.\n",
    "lockdowns = lockdowns.explode('Date_Range')\n",
    "lockdowns = lockdowns[['Province', 'Date_Range']]\n",
    "lockdowns.drop_duplicates(inplace = True)\n",
    "\n",
    "#Reading Province\n",
    "folder = 'Mapping Files'\n",
    "file = 'SA_Site_Mapping.xlsx'\n",
    "sites = pd.read_excel(os.path.join(directory,folder,file))\n",
    "sites = sites[sites['Site Status'] != 'Inactive']\n",
    "sites = sites[['Ship To Party Code', 'Plant Code', 'Province']]\n",
    "sites.drop_duplicates(inplace = True)\n",
    "\n",
    "\n",
    "# Writing Lockdowns\n",
    "filename = 'lockdowns.csv'\n",
    "write_path = os.path.join(directory,subfolder,subfolder_1,filename)\n",
    "sites.to_csv(write_path)\n",
    "\n",
    "# Writing Province\n",
    "filename = 'province.csv'\n",
    "write_path = os.path.join(directory,subfolder,subfolder_1,filename)\n",
    "sites.to_csv(write_path)\n",
    "\n",
    "# Adding Lockdowns\n",
    "full_data_timeseries = pd.merge(full_data_timeseries,sites,\n",
    "    left_on =['Ship To', 'Receiving Plant Code'], \n",
    "    right_on = ['Ship To Party Code','Plant Code'], how = 'left')\n",
    "full_data_timeseries = pd.merge(full_data_timeseries,lockdowns, left_on = ['Province','date'], right_on = ['Province','Date_Range'], how = 'left')\n",
    "\n",
    "full_data_timeseries = full_data_timeseries.drop(\"Ship To Party Code\" ,axis = 1)\n",
    "full_data_timeseries = full_data_timeseries.drop(\"Plant Code\" ,axis = 1)\n",
    "full_data_timeseries['LockDown Flag'] = full_data_timeseries['Date_Range'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "full_data_timeseries = full_data_timeseries.drop('Date_Range', axis =1)\n",
    "\n",
    "full_data_timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Depot mapping\n",
    "folder = 'Mapping Files'\n",
    "file = 'SA_Depot_Mapping.xlsx'\n",
    "depots = pd.read_excel(os.path.join(directory,folder,file))[['Plant','Region']]\n",
    "depots.drop_duplicates(inplace = True)\n",
    "\n",
    "folder = 'Mapping Files'\n",
    "file = 'SA_Material_Mapping.xlsx'\n",
    "materials = pd.read_excel(os.path.join(directory,folder,file))[['Material Number','Grade Type']]\n",
    "materials.drop_duplicates(inplace = True)\n",
    "\n",
    "#Adding Region and Grade Type\n",
    "full_data_timeseries = pd.merge(full_data_timeseries,depots,left_on = \n",
    "        ['Receiving Plant Code'], right_on = ['Plant'], how ='left')\n",
    "\n",
    "full_data_timeseries = full_data_timeseries.drop('Plant', axis = 1)\n",
    "full_data_timeseries = pd.merge(full_data_timeseries,materials, on = ['Material Number'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624953, 21)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Price Details\n",
    "folder = 'External Variables'\n",
    "file = 'SA Price Information.xlsx'\n",
    "price = pd.read_excel(os.path.join(directory,folder,file))\n",
    "\n",
    "price.sort_values(by=['Location','Grade Type','Date'] , inplace = True)\n",
    "\n",
    "price['End Date'] = price.groupby(['Location','Grade Type'])['Date'].shift(-1)\n",
    "max_date = max(price['Date'])\n",
    "price['End Date'] = price['End Date'].fillna(max_date.date().strftime('%Y-%m-%d'))\n",
    "price['Date_Range'] = price.apply(lambda x: daterange(x['Date'] , x['End Date']), axis =1)\n",
    "price = price.explode('Date_Range')\n",
    "price = price[price['Date_Range'] < price['End Date']]\n",
    "price = price[['Location','Grade Type','Date_Range','Fuel Price']]\n",
    "\n",
    "agg = {\n",
    "    'Fuel Price': 'mean'\n",
    "}\n",
    "price = price.groupby(['Grade Type', 'Date_Range']).aggregate(agg).reset_index()\n",
    "\n",
    "price.drop_duplicates(inplace=True)\n",
    "\n",
    "filname = 'price.csv'\n",
    "write_path = os.path.join(directory,subfolder,subfolder_1,filename)\n",
    "price.to_csv(write_path)\n",
    "\n",
    "full_data_timeseries = pd.merge(full_data_timeseries , price,left_on =['Grade Type',\n",
    "    'date'],right_on=['Grade Type','Date_Range'],how = 'left')\n",
    "\n",
    "full_data_timeseries = full_data_timeseries.drop('Date_Range',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624953, 22)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624953, 29)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading loyalty programs\n",
    "agg = {\n",
    "    'Estimated Budget in ZAR': 'sum',\n",
    "    'Campaign Description':'nunique'\n",
    "}\n",
    "\n",
    "folder = 'External Variables'\n",
    "file = 'SA Retail Loyalty Data.xlsx'\n",
    "loyalty = pd.read_excel(os.path.join(directory,folder,file))\n",
    "loyalty= loyalty[['Campaign Description','Estimated Budget in ZAR','Start Date','End Date']]\n",
    "\n",
    "loyalty['Estimated Budget in ZAR'] = pd.to_numeric(loyalty['Estimated Budget in ZAR'],errors='coerce')\n",
    "loyalty['Campaign Description'] = loyalty['Campaign Description'].astype(str)\n",
    "\n",
    "loyalty = loyalty.dropna(subset=['Estimated Budget in ZAR'])\n",
    "loyalty['Date_Range'] = loyalty.apply(lambda x: daterange(x['Start Date'], x['End Date']),axis=1)\n",
    "loyalty = loyalty.explode('Date_Range')\n",
    "loyalty = loyalty[['Campaign Description','Estimated Budget in ZAR','Date_Range']]\n",
    "loyalty = loyalty.groupby('Date_Range').aggregate(agg).reset_index()\n",
    "\n",
    "#Reading Marketing Programes\n",
    "agg = {\n",
    "    'Estimated Budget in USD': 'sum',\n",
    "    'Potential Impact Percentage': 'mean',\n",
    "    'Campaign Name/ID': 'nunique'\n",
    "}\n",
    "folder = 'External Variables'\n",
    "file = 'SA Retail Marketing Data.xlsx'\n",
    "marketing = pd.read_excel(os.path.join(directory,folder,file))\n",
    "marketing = marketing[['Campaign Name/ID','Estimated Budget in USD',\n",
    "                'Potential Impact Percentage','Start Date','End Date']]\n",
    "marketing['Date_Range'] = marketing.apply(lambda x: daterange(x['Start Date'],\n",
    "            x['End Date']),axis=1)\n",
    "\n",
    "marketing = marketing.explode('Date_Range')\n",
    "marketing = marketing[['Campaign Name/ID','Estimated Budget in USD','Potential Impact Percentage','Date_Range']]\n",
    "marketing = marketing.groupby('Date_Range').aggregate(agg).reset_index()\n",
    "\n",
    "# writing loyalty\n",
    "filname = 'loyalty.csv'\n",
    "write_path = os.path.join(directory,subfolder,subfolder_1,filename)\n",
    "marketing.to_csv(write_path)\n",
    "\n",
    "# Adding Loyalty\n",
    "full_data_timeseries = pd.merge(full_data_timeseries,loyalty,\n",
    "    left_on = ['date'], right_on = ['Date_Range'], how = 'left')\n",
    "\n",
    "full_data_timeseries['Loyalty Flag'] = full_data_timeseries['Date_Range'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "full_data_timeseries = full_data_timeseries.drop('Date_Range', axis=1)\n",
    "\n",
    "#Marketing\n",
    "full_data_timeseries = pd.merge(full_data_timeseries , marketing,\n",
    "    left_on = ['date'], right_on = ['Date_Range'], how = 'left')\n",
    "full_data_timeseries['Marketing Flag'] = full_data_timeseries['Date_Range'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "full_data_timeseries = full_data_timeseries.drop('Date_Range', axis = 1)\n",
    "\n",
    "full_data_timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing data\n",
    "folder = 'EDA'\n",
    "filename = 'ProcessedData.csv'\n",
    "write_path = os.path.join(directory,folder,filename)\n",
    "full_data_timeseries.to_csv(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624953, 29)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_timeseries[full_data_timeseries['date'] == '2019-01-01'].to_csv(os.path.join(directory,folder,'Check.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = {\n",
    "    'Sales Volumes in L15': 'sum',\n",
    "    'Holiday Flag': 'max',\n",
    "    'Holiday Desc': 'max'\n",
    "}\n",
    "holidays_eda = full_data_timeseries.groupby(['Material Number','date']).aggregate(agg).reset_index()\n",
    "\n",
    "agg = {\n",
    "    'Sales Volumes in L15': 'sum',\n",
    "    'LockDown Flag': 'max'\n",
    "}\n",
    "lockdowns_eda = full_data_timeseries.groupby(['Material Number',\n",
    "    'Province','date']).aggregate(agg).reset_index()\n",
    "\n",
    "agg = {\n",
    "    'Sales Volumes in L15': 'sum',\n",
    "    'Fuel Price': 'mean'\n",
    "}\n",
    "price_eda = full_data_timeseries.groupby(['Material Number','date']).aggregate(agg).reset_index()\n",
    "\n",
    "agg = {      \n",
    "    'Sales Volumes in L15': 'sum',\n",
    "    'Loyalty Flag': 'max',\n",
    "    'Estimated Budget in ZAR': 'max'\n",
    "}\n",
    "loyalty_eda = full_data_timeseries.groupby(['Material Number','date']).aggregate(agg).reset_index()\n",
    "\n",
    "agg = {\n",
    "    'Sales Volumes in L15': 'sum',\n",
    "    'Marketing Flag': 'max',\n",
    "    'Estimated Budget in USD': 'max'\n",
    "    \n",
    "}\n",
    "marketing_eda = full_data_timeseries.groupby(['Material Number','date']).aggregate(agg).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_eda['Month'] = holidays_eda.date.dt.month\n",
    "holidays_eda['Day'] = holidays_eda['date'].dt.dayofyear\n",
    "\n",
    "lockdowns_eda['Month'] = lockdowns_eda.date.dt.month\n",
    "lockdowns_eda['Day'] = lockdowns_eda['date'].dt.dayofyear\n",
    "\n",
    "price_eda['Month'] = price_eda.date.dt.month\n",
    "price_eda['Day'] = price_eda['date'].dt.dayofyear\n",
    "\n",
    "loyalty_eda['Month'] = loyalty_eda.date.dt.month\n",
    "loyalty_eda['Day'] = loyalty_eda['date'].dt.dayofyear\n",
    "\n",
    "marketing_eda['Month'] = marketing_eda.date.dt.month\n",
    "marketing_eda['Day'] = marketing_eda['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'EDA'\n",
    "filename = 'Holidays_EDA.csv'\n",
    "write_path = os.path.join(directory,folder,filename)\n",
    "holidays_eda.to_csv(write_path)\n",
    "\n",
    "folder = 'EDA'\n",
    "filename = 'Lockdowns_EDA.csv'\n",
    "write_path = os.path.join(directory,folder,filename)\n",
    "lockdowns_eda.to_csv(write_path)\n",
    "\n",
    "folder = 'EDA'\n",
    "filename = 'FuelPrice_EDA.csv'\n",
    "write_path = os.path.join(directory,folder,filename)\n",
    "price_eda.to_csv(write_path)\n",
    "\n",
    "folder = 'EDA'\n",
    "filename = 'Loyalty_EDA.csv'\n",
    "write_path = os.path.join(directory,folder,filename)\n",
    "loyalty_eda.to_csv(write_path)\n",
    "\n",
    "folder = 'EDA'\n",
    "filename = 'Marketing_EDA.csv'\n",
    "write_path = os.path.join(directory,folder,filename)\n",
    "marketing_eda.to_csv(write_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
